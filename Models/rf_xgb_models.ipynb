{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a few models on the df2 dataset.  In particular, we consider a random forest classifier and a XGBoost classifier, wrapped in a MultiOutputClassifier for the purpose of multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load up the three DataFrames constructed from the data analysis notebook.  However, as indicated in that notebook,\n",
    "# we will only focus on df2.\n",
    "\n",
    "df1 = pd.read_pickle('../electronic_df_EDAv1.pkl')\n",
    "df2 = pd.read_pickle('../electronic_df_EDAv2.pkl')\n",
    "df3 = pd.read_pickle('../electronic_df_EDAv3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data to be fed into our model\n",
    "labels = ['mbdata.techno', 'mbdata.house', 'mbdata.trance', 'mbdata.dnb']\n",
    "drop_cols = ['mbdata.id', 'mbdata.title', 'mbdata.artist-name', 'mbdata.artist-id',\n",
    "             'mbdata.all-tags', 'mbdata.genre']\n",
    "\n",
    "X1 = df1.drop(columns=drop_cols+labels)\n",
    "y1 = df1[labels]\n",
    "X2 = df2.drop(columns=drop_cols+labels)\n",
    "y2 = df2[labels]\n",
    "X3 = df3.drop(columns=drop_cols+labels)\n",
    "y3 = df3[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=415)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=415)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train a dummy classifier as a baseline model.\n",
    "# The stratified strategy predicts based on the distribution of labels in\n",
    "# our dataset.\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=415)\n",
    "dummy_multi = MultiOutputClassifier(dummy, n_jobs=-1)\n",
    "dummy_multi.fit(X2_train, y2_train)\n",
    "\n",
    "y2_pred_dummy = dummy_multi.predict(X2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.5828129242465382\n",
      "\n",
      "mbdata.techno    0.582949\n",
      "mbdata.house     0.523894\n",
      "mbdata.trance    0.591501\n",
      "mbdata.dnb       0.632908\n",
      "dtype: float64\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "mbdata.techno       0.30      0.30      0.30      2207\n",
      " mbdata.house       0.40      0.41      0.41      2943\n",
      "mbdata.trance       0.28      0.28      0.28      2111\n",
      "   mbdata.dnb       0.24      0.24      0.24      1769\n",
      "\n",
      "    micro avg       0.32      0.32      0.32      9030\n",
      "    macro avg       0.31      0.31      0.31      9030\n",
      " weighted avg       0.32      0.32      0.32      9030\n",
      "  samples avg       0.13      0.31      0.17      9030\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "tot_acc = (y2_test == y2_pred_dummy).values.flatten().mean()\n",
    "genre_acc = (y2_test == y2_pred_dummy).mean()\n",
    "report = classification_report(y2_test, y2_pred_dummy, target_names=labels)\n",
    "\n",
    "print(f'Total Accuracy: {tot_acc}')\n",
    "print()\n",
    "print(genre_acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "12 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n",
      "    return self.func(**kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\multioutput.py\", line 61, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\multioutput.py\", line 537, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\multioutput.py\", line 272, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 1754, in _retrieve\n",
      "    self._raise_error_fast()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 1789, in _raise_error_fast\n",
      "    error_job.get_result(self.timeout)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 745, in get_result\n",
      "    return self._return_or_raise()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 763, in _return_or_raise\n",
      "    raise self._result\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n",
      "    return self.func(**kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\multioutput.py\", line 61, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\multioutput.py\", line 537, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\multioutput.py\", line 272, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 1754, in _retrieve\n",
      "    self._raise_error_fast()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 1789, in _raise_error_fast\n",
      "    error_job.get_result(self.timeout)\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 745, in get_result\n",
      "    return self._return_or_raise()\n",
      "  File \"c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\joblib\\parallel.py\", line 763, in _return_or_raise\n",
      "    raise self._result\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.32895496 0.38736721 0.38543258        nan\n",
      " 0.45735329 0.33173811        nan 0.4268065 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__n_estimators': 500, 'estimator__min_samples_split': 10, 'estimator__min_samples_leaf': 4, 'estimator__max_features': 'sqrt', 'estimator__max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# Performing a RandomSearchCV for hyperparameter tuning\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "base_estimator = RandomForestClassifier(random_state=415)\n",
    "\n",
    "param_distributions = {\n",
    "    'estimator__n_estimators': [100, 200, 500],\n",
    "    'estimator__max_depth': [None, 10, 20],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "multi_output_model = MultiOutputClassifier(base_estimator, n_jobs=-1)\n",
    "\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(estimator=multi_output_model, \n",
    "                                   param_distributions=param_distributions, \n",
    "                                   n_iter=10, cv=3, verbose=2, n_jobs=-1, random_state=42)\n",
    "random_search_rf.fit(X2_train, y2_train)\n",
    "\n",
    "print(random_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For posterity, the best parameters from the above RandomSearchCV are:\n",
    "{'estimator__n_estimators': 500, 'estimator__min_samples_split': 10, 'estimator__min_samples_leaf': 4, 'estimator__max_features': 'sqrt', 'estimator__max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model with best_params\n",
    "rf = random_search_rf.best_estimator_\n",
    "y2_pred_rf = rf.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.8206625033939723\n",
      "\n",
      "mbdata.techno    0.784686\n",
      "mbdata.house     0.757942\n",
      "mbdata.trance    0.853516\n",
      "mbdata.dnb       0.886506\n",
      "dtype: float64\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "mbdata.techno       0.76      0.41      0.53      2207\n",
      " mbdata.house       0.79      0.54      0.64      2943\n",
      "mbdata.trance       0.91      0.54      0.68      2111\n",
      "   mbdata.dnb       0.91      0.59      0.71      1769\n",
      "\n",
      "    micro avg       0.84      0.52      0.64      9030\n",
      "    macro avg       0.84      0.52      0.64      9030\n",
      " weighted avg       0.83      0.52      0.64      9030\n",
      "  samples avg       0.60      0.56      0.57      9030\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "tot_acc = (y2_test == y2_pred_rf).values.flatten().mean()\n",
    "genre_acc = (y2_test == y2_pred_rf).mean()\n",
    "report = classification_report(y2_test, y2_pred_rf, target_names=labels)\n",
    "\n",
    "print(f'Total Accuracy: {tot_acc}')\n",
    "print()\n",
    "print(genre_acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base estimator\n",
    "xgb_model = XGBClassifier(objective='binary:logistic', \n",
    "                          eval_metric='logloss', \n",
    "                          use_label_encoder=False,\n",
    "                          tree_method='gpu_hist', # using GPU\n",
    "                          predictor='gpu_predictor')\n",
    "\n",
    "# Parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'estimator__n_estimators': [100, 200, 500],\n",
    "    'estimator__max_depth': [3, 5, 7, 10],\n",
    "    'estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'estimator__subsample': [0.6, 0.8, 1.0],\n",
    "    'estimator__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Wrap XGBClassifier with MultiOutputClassifier\n",
    "multi_output_model = MultiOutputClassifier(xgb_model, n_jobs=-1)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=multi_output_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of parameter settings sampled\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,  # Verbosity level\n",
    "    n_jobs=-1,  # Use all processors\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "xgb_random_search.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the RandomizedSearchCV, we obtain parameters:\n",
    "Best Parameters: {'estimator__subsample': 1.0, 'estimator__n_estimators': 500, 'estimator__max_depth': 10, 'estimator__learning_rate': 0.1, 'estimator__colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.8, device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;logloss&#x27;,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.1, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=10,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=500, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=415, ...),\n",
       "                      n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultiOutputClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\">?<span>Documentation for MultiOutputClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.8, device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;logloss&#x27;,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.1, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=10,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=500, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=415, ...),\n",
       "                      n_jobs=-1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=415, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=415, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.8, device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric='logloss',\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.1, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=10,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=500, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=415, ...),\n",
       "                      n_jobs=-1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running XGBClassifier on the above best parameters.\n",
    "# We will do this manually to not re-run the RandomizedSearchCV.\n",
    "\n",
    "xgb_model = XGBClassifier(objective='binary:logistic', \n",
    "                          eval_metric='logloss', \n",
    "                          subsample=1.0,\n",
    "                          n_estimators=500,\n",
    "                          max_depth=10,\n",
    "                          learning_rate=0.1,\n",
    "                          colsample_bytree=0.8,\n",
    "                          use_label_encoder=False,\n",
    "                          random_state=415\n",
    "                          )\n",
    "\n",
    "xgb_model_multi = MultiOutputClassifier(xgb_model, n_jobs=-1)\n",
    "\n",
    "xgb_model_multi.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred_xgb = xgb_model_multi.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.8458457778984524\n",
      "\n",
      "mbdata.techno    0.802742\n",
      "mbdata.house     0.789438\n",
      "mbdata.trance    0.882297\n",
      "mbdata.dnb       0.908906\n",
      "dtype: float64\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "mbdata.techno       0.76      0.50      0.60      2207\n",
      " mbdata.house       0.77      0.67      0.72      2943\n",
      "mbdata.trance       0.87      0.70      0.77      2111\n",
      "   mbdata.dnb       0.87      0.73      0.79      1769\n",
      "\n",
      "    micro avg       0.81      0.65      0.72      9030\n",
      "    macro avg       0.82      0.65      0.72      9030\n",
      " weighted avg       0.81      0.65      0.72      9030\n",
      "  samples avg       0.73      0.69      0.69      9030\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tot_acc = (y2_test == y2_pred_xgb).values.flatten().mean()\n",
    "genre_acc = (y2_test == y2_pred_xgb).mean()\n",
    "report = classification_report(y2_test, y2_pred_xgb, target_names=labels)\n",
    "\n",
    "print(f'Total Accuracy: {tot_acc}')\n",
    "print()\n",
    "print(genre_acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base logistic regression model\n",
    "logistic = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Wrap it with MultiOutputClassifier\n",
    "multi_target_lr = MultiOutputClassifier(logistic, n_jobs=-1)\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'estimator__C': uniform(loc=0, scale=4),  # C parameter for Logistic Regression\n",
    "    'estimator__penalty': ['l1', 'l2'],  # Penalty type\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    multi_target_lr, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10,  # Number of iterations\n",
    "    cv=3,  # 5-fold cross-validation\n",
    "    scoring='accuracy',  # Evaluation metric\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=415\n",
    ")\n",
    "\n",
    "random_search_lr.fit(X2, y2)\n",
    "\n",
    "print(\"Best parameters found:\", random_search_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_lr.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred_lr = multi_output_logi.predict(X2_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mbdata.techno    0.700380\n",
       "mbdata.house     0.600462\n",
       "mbdata.trance    0.713413\n",
       "mbdata.dnb       0.759843\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y2_test == y2_pred_logi).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935243008417051"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y2_test == y2_pred_logi).values.flatten().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'               precision    recall  f1-score   support\\n\\nmbdata.techno       0.00      0.00      0.00      2207\\n mbdata.house       0.00      0.00      0.00      2943\\nmbdata.trance       0.00      0.00      0.00      2111\\n   mbdata.dnb       0.00      0.00      0.00      1769\\n\\n    micro avg       0.00      0.00      0.00      9030\\n    macro avg       0.00      0.00      0.00      9030\\n weighted avg       0.00      0.00      0.00      9030\\n  samples avg       0.00      0.00      0.00      9030\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y2_test, y2_pred_logi, zero_division=0, target_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# trying a different threshold\n",
    "y2_pred_logi_prob = multi_output_logi.predict_proba(X2_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "y2_pred_logi_thres = np.array([\n",
    "    (probs[:, 1] >= thresholds[i]).astype(int)\n",
    "    for i, probs in enumerate(y2_pred_logi_prob)\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbdata.techno    0.700380\n",
      "mbdata.house     0.600462\n",
      "mbdata.trance    0.713413\n",
      "mbdata.dnb       0.759843\n",
      "dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2207\n",
      "           1       0.00      0.00      0.00      2943\n",
      "           2       0.00      0.00      0.00      2111\n",
      "           3       0.00      0.00      0.00      1769\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      9030\n",
      "   macro avg       0.00      0.00      0.00      9030\n",
      "weighted avg       0.00      0.00      0.00      9030\n",
      " samples avg       0.00      0.00      0.00      9030\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print((y2_pred_logi_thres == y2_test).mean())\n",
    "\n",
    "print(classification_report(y2_test, y2_pred_logi_thres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weighted_random_predictions(X, label_probabilities):\n",
    "    \"\"\"\n",
    "    Generate random binary predictions for multi-label classification based on label probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: DataFrame or array-like, shape (n_samples, n_features)\n",
    "    - label_probabilities: list or array, shape (num_labels,), probabilities of each label being assigned\n",
    "    \n",
    "    Returns:\n",
    "    - y_pred_weighted: array, shape (n_samples, num_labels)\n",
    "    \"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    num_labels = len(label_probabilities)\n",
    "    \n",
    "    # Generate random binary predictions based on label probabilities\n",
    "    y_pred_weighted = np.zeros((num_samples, num_labels))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_labels):\n",
    "            if np.random.rand() < label_probabilities[j]:\n",
    "                y_pred_weighted[i, j] = 1\n",
    "    \n",
    "    return y_pred_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "techno_pro = (y2['mbdata.techno'].sum())/len(y2)\n",
    "house_pro = (y2['mbdata.house'].sum())/len(y2)\n",
    "trance_pro = (y2['mbdata.trance'].sum())/len(y2)\n",
    "dnb_pro = (y2['mbdata.dnb'].sum())/len(y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_probabilities = [techno_pro, house_pro, trance_pro, dnb_pro]\n",
    "y2_pred_rand = generate_weighted_random_predictions(X2_test, label_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mbdata.techno    0.576025\n",
       "mbdata.house     0.518463\n",
       "mbdata.trance    0.593402\n",
       "mbdata.dnb       0.638746\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y2_pred_rand == y2_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kling\\anaconda3\\envs\\erdos_may_2024\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'               precision    recall  f1-score   support\\n\\nmbdata.techno       0.29      0.29      0.29      2207\\n mbdata.house       0.40      0.42      0.41      2943\\nmbdata.trance       0.29      0.28      0.28      2111\\n   mbdata.dnb       0.25      0.25      0.25      1769\\n\\n    micro avg       0.32      0.32      0.32      9030\\n    macro avg       0.31      0.31      0.31      9030\\n weighted avg       0.32      0.32      0.32      9030\\n  samples avg       0.25      0.32      0.26      9030\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y2_test, y2_pred_rand, target_names=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
